# import packages:
import pandas as pd
pd.set_option('future.no_silent_downcasting', True) # to handle future changes.
import numpy as np
import pathlib
from typing import Union, Tuple
import matplotlib.pyplot as plt
import re

class QuestionnaireAnalysis:
    """
    Reads and analyzes data generated by the questionnaire experiment.
    Should be able to accept strings and pathlib.Path objects.
    """

    def __init__(self, data_fname: Union[pathlib.Path, str]):
        self.data_fname = pathlib.Path(data_fname)
        if not self.data_fname.is_file():
            raise ValueError(f"File {self.data_fname} does not exist.") # Raise error if file does not exist
        self.data = pd.DataFrame() # Initialize a DataFrame

    def read_data(self):
        """Reads the json data located in self.data_fname into memory, to
        the attribute self.data.
        """
        self.data = pd.read_json(self.data_fname) # Load the data into DataFrame

    def show_age_distrib(self) -> Tuple[np.ndarray, np.ndarray]:
        """Calculates and plots the age distribution of the participants.

        Returns
        -------
        hist : np.ndarray
            Number of people in a given bin
        bins : np.ndarray
            Bin edges
        """
        ages = self.data['age'].dropna() # remove the missing values from the 'age' column
        bins = np.arange(0, 101, 10) # Define bins for histogram
        hist, _ = np.histogram(ages, bins=bins)  # Compute histogram
        plt.hist(ages, bins=bins, edgecolor='blue', color='lightblue')
        plt.title('Age Distribution')
        plt.xlabel('Age')
        plt.ylabel('Number of Participants')
        plt.grid(True)
        plt.show()
        return hist, bins

    def remove_rows_without_mail(self) -> pd.DataFrame:
        """Checks self.data for rows with invalid emails, and removes them.

        Returns
        -------
        df : pd.DataFrame
            A corrected DataFrame, i.e. the same table but with the erroneous rows removed and
            the (ordinal) index after a reset.
        """
        def is_valid_email(email: str) -> bool:
            pattern = r'^[^@]+@[^@]+\.[^@]+$' # Define the pattern for valid email
            return bool(re.match(pattern, email)) # Return True if email matches the valid pattern

    # Apply the email validation function correctly
        valid_emails = self.data['email'].apply(is_valid_email) # Apply validation function
        valid_email_df = self.data[valid_emails].reset_index(drop=True) # Filter valid emails and reset index
        self.data = valid_email_df # Update the DataFrame with the valid emails
        return self.data # Return updated DataFrame

    def fill_na_with_mean(self) -> Tuple[pd.DataFrame, np.ndarray]:
        """Finds, in the original DataFrame, the subjects that didn't answer
        all questions, and replaces that missing value with the mean of the
        other grades for that student.

        Returns
        -------
        df : pd.DataFrame
            The corrected DataFrame after insertion of the mean grade
        arr : np.ndarray
            Row indices of the students that their new grades were generated
        """
        grade_columns = ['q1', 'q2', 'q3', 'q4', 'q5'] # List of grade columns
        missing_data_rows = self.data[grade_columns].isnull().any(axis=1) # select rows with missing data
        missing_indices = np.where(missing_data_rows)[0] # find indices of rows with missing data

        for i in missing_indices:
            row_mean = self.data.loc[i, grade_columns].mean() # Compute mean of the available grades
            self.data.loc[i, grade_columns] = self.data.loc[i, grade_columns].fillna(row_mean) # Fill missing values with the mean 

        return self.data, missing_indices  # Return updated DataFrame and indices of rows with missing data

    def score_subjects(self, maximal_nans_per_sub: int = 1) -> pd.DataFrame:
        """Calculates the average score of a subject and adds a new "score" column
        with it.

        If the subject has more than "maximal_nans_per_sub" NaN in his grades, the
        score should be NA. Otherwise, the score is simply the mean of the other grades.
        The datatype of score is UInt8, and the floating point raw numbers should be
        rounded down.

        Parameters
        ----------
        maximal_nans_per_sub : int, optional
            Number of allowed NaNs per subject before giving a NA score.

        Returns
        -------
        pd.DataFrame
            A new DF with a new column - "score".
        """
        grade_columns = ['q1', 'q2', 'q3', 'q4', 'q5'] # List of grade columns
        self.data['score'] = self.data[grade_columns].apply(lambda x: np.floor(x.mean()) if x.isnull().sum() <= maximal_nans_per_sub else pd.NA, # Compute score or NA
            axis=1).astype("UInt8", errors='ignore')  # Convert scores to UInt8 type
        return self.data # Return DataFrame with scores

    def correlate_gender_age(self) -> pd.DataFrame:
        """Looks for a correlation between the gender of the subject, their age
        and the score for all five questions.

        Returns
        -------
        pd.DataFrame
            A DataFrame with a MultiIndex containing the gender and whether the subject is above
            40 years of age, and the average score in each of the five questions.
        """
        age_valid_data = self.data[self.data['age'].notna()].copy() # Filter out rows with missing 'age' and make a copy of the DataFrame
        age_valid_data['age_category'] = age_valid_data['age'].apply(lambda age: age > 40)  # Create a new column to indicate if the age is above 40
        grouped_data = age_valid_data.groupby(['gender', 'age_category'])[['q1', 'q2', 'q3', 'q4', 'q5']].mean() # Group the data by 'gender' and 'age_category' and calculate the mean of each question
        grouped_data.index = grouped_data.index.set_names('age', level=1) # Rename the 'age_category' index level to 'age'
        return grouped_data # Return grouped DataFrame
